{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88769eb3-d074-4394-a0c1-7a407825666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, ReLU, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a89f13-9150-413b-9d3a-cea31a2813cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57aa9fd-f26c-47c0-8f18-a061dc50018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "trainX=trainX/255\n",
    "testX=testX/255\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f543627-6aaf-4093-8e14-4e543c7d4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "\n",
    "    initial_lrate=0.001\n",
    "    step_size=10\n",
    "    decay_factor=0.5\n",
    "    new_lr=initial_lrate * (decay_factor ** np.floor(epoch/step_size))\n",
    "    print(new_lr,epoch)\n",
    "    return new_lr\n",
    "\n",
    "class VariationalAutoEncoder():\n",
    "\n",
    "    _ENC_FILTERS = [32,64,64,64]\n",
    "    _ENC_STRIDES = [1,2,2,1]\n",
    "    _FILTER_SIZE = [3,3,3,3]\n",
    "    _LATENT_SPACE = 32\n",
    "    _DEC_FILTERS = [64,64,32,1]\n",
    "    _DEC_STRIDES = [1,2,2,1]\n",
    "    _BATCH_NORM = True\n",
    "    _DROPOUT = 0.2\n",
    "\n",
    "    def __init__(self,input_dim):\n",
    "\n",
    "        self.input_dim=input_dim\n",
    "        #self._build()\n",
    "\n",
    "    def _build_encoder(self):\n",
    "\n",
    "        encoder_input=Input(shape=self.input_dim,name='encoder_input')\n",
    "        x=encoder_input\n",
    "\n",
    "        for lyr in range(len(self._ENC_FILTERS)):\n",
    "\n",
    "            conv_layer=Conv2D(filters=self._ENC_FILTERS[lyr],\n",
    "                              kernel_size=self._FILTER_SIZE[lyr],\n",
    "                              strides=self._ENC_STRIDES[lyr],\n",
    "                              name='encoder_conv'+str(lyr),\n",
    "                              padding ='same')\n",
    "            x=conv_layer(x)\n",
    "            x=ReLU()(x)\n",
    "\n",
    "            if self._BATCH_NORM==True:\n",
    "                x=BatchNormalization()(x)\n",
    "\n",
    "        shape_before_flattening=K.int_shape(x)[1:]\n",
    "        x=Flatten()(x)\n",
    "\n",
    "        self.mu = Dense(self._LATENT_SPACE, name='mu')(x)\n",
    "        self.log_var = Dense(self._LATENT_SPACE, name='log_var')(x)\n",
    "        encoder_mu_log_var = Model(encoder_input, (self.mu, self.log_var))\n",
    "\n",
    "        def sampling(args):\n",
    "            mu, log_var = args\n",
    "            epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
    "            return mu + K.exp(log_var / 2) * epsilon\n",
    "        \n",
    "        encoder_output = Lambda(sampling, name='encoder_output')([self.mu, self.log_var])\n",
    "        encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def _build_decoder(self,shape_before_flattening):\n",
    "\n",
    "        decoder_input=Input(shape=self._LATENT_SPACE,name='decoder_input')\n",
    "        x=Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "        x=Reshape(shape_before_flattening)(x)\n",
    "\n",
    "        for lyr in range(len(self._DEC_FILTERS)):\n",
    "\n",
    "            conv_t_layer=Conv2DTranspose(filters=self._DEC_FILTERS[lyr],\n",
    "                                         kernel_size=self._FILTER_SIZE[lyr],\n",
    "                                         strides=self._DEC_STRIDES[lyr],\n",
    "                                         name='decoder_conv_t'+str(lyr),\n",
    "                                         padding ='same')\n",
    "            x=conv_t_layer(x)\n",
    "\n",
    "            if lyr<len(self._DEC_FILTERS)-1:\n",
    "\n",
    "                x=ReLU()(x)\n",
    "\n",
    "                if self._BATCH_NORM==True:\n",
    "                    x = BatchNormalization()(x)\n",
    "            else:\n",
    "                x=Activation('sigmoid')(x)\n",
    "\n",
    "        decoder_output=x\n",
    "        decoder=Model(decoder_input,decoder_output, name = 'Decoder')\n",
    "        return decoder\n",
    "\n",
    "    def fit(self,Xtr,Xval,**kwargs):\n",
    "\n",
    "        self.initial_lr = kwargs.get(\"initial_lr\", 0.001)\n",
    "        self.batch_size = kwargs.get(\"batch_size\", 32)\n",
    "        self.callbacks_list = kwargs.get(\"callbacks_list\", [])\n",
    "        self.epochs = kwargs.get(\"epochs\", 100)\n",
    "        self.shuffle = kwargs.get(\"shuffle\", True)\n",
    "\n",
    "        model, decoder, encoder = self.get_model()\n",
    "\n",
    "        model.fit(Xtr, Xtr,\n",
    "                       batch_size=self.batch_size,\n",
    "                       validation_data=(Xval,Xval),\n",
    "                       shuffle=self.shuffle,\n",
    "                       epochs=self.epochs,\n",
    "                       callbacks=self.callbacks_list)\n",
    "\n",
    "        self.model = model\n",
    "        self.decoder = decoder\n",
    "        self.encoder = encoder\n",
    "\n",
    "\n",
    "    def get_model(self):\n",
    "\n",
    "        #Autoencoder Layer\n",
    "        encoder = self._build_encoder()\n",
    "        shape_before_flattening = encoder.layers[-5].get_output_at(0).get_shape().as_list()[1:]\n",
    "        decoder = self._build_decoder(shape_before_flattening)\n",
    "\n",
    "        model_input = Input(shape=self.input_dim,name='encoder_input')\n",
    "        encoder_op = encoder(model_input)\n",
    "        decoder_op = decoder(encoder_op)\n",
    "\n",
    "        model = Model(model_input,decoder_op,name='ae_model')\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                           loss = 'mean_squared_error',\n",
    "                           )\n",
    "\n",
    "        return model, decoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06022877-dfb8-464b-976b-4b4b7d0b8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder(input_dim=(28,28,1))\n",
    "model, decoder, encoder = vae.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c298bd06-4ce8-42b4-ace2-7d1305124b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " encoder_conv0 (Conv2D)         (None, 28, 28, 32)   320         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 28, 28, 32)   0           ['encoder_conv0[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 28, 28, 32)  128         ['re_lu_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " encoder_conv1 (Conv2D)         (None, 14, 14, 64)   18496       ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 14, 14, 64)   0           ['encoder_conv1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 14, 14, 64)  256         ['re_lu_5[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " encoder_conv2 (Conv2D)         (None, 7, 7, 64)     36928       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 7, 7, 64)     0           ['encoder_conv2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 7, 7, 64)    256         ['re_lu_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " encoder_conv3 (Conv2D)         (None, 7, 7, 64)     36928       ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 7, 7, 64)     0           ['encoder_conv3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 7, 64)    256         ['re_lu_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 3136)         0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 32)           100384      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " log_var (Dense)                (None, 32)           100384      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " encoder_output (Lambda)        (None, 32)           0           ['mu[0][0]',                     \n",
      "                                                                  'log_var[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 294,336\n",
      "Trainable params: 293,888\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6ef24-7ff4-42de-82f5-5f10ebea6e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
